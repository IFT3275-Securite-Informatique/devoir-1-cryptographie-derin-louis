{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapport du Devoir 1, IFT3275-A\n",
    "\n",
    "Auteurs:\n",
    "-    Ding Jun QIU, 20046157\n",
    "-    Mahamadou Maiga, 20223386\n",
    "-    Abdoul Karim Ouattara, 20202656"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a better reading experience, please read the HTML version of this report, or better, the .ipynb attached in sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decimal as d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "The code related to Q1.1 is found in 'devoir1.py'\n",
    "\n",
    "Codes related to Q1.2 are inside this document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clé publique Question 1.1\n",
    "q1_N = 143516336909281815529104150147210248002789712761086900059705342103220782674046289232082435789563283739805745579873432846680889870107881916428241419520831648173912486431640350000860973935300056089286158737579357805977019329557985454934146282550582942463631245697702998511180787007029139561933433550242693047924440388550983498690080764882934101834908025314861468726253425554334760146923530403924523372477686668752567287060201407464630943218236132423772636675182977585707596016011556917504759131444160240252733282969534092869685338931241204785750519748505439039801119762049796085719106591562217115679236583\n",
    "q1_e = 3\n",
    "\n",
    "# Cryptogramme 1.1\n",
    "q1_C = 1101510739796100601351050380607502904616643795400781908795311659278941419415375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using N-th root attack!\n",
      "The deciphered M is: 103275247704828660521722734\n",
      "The UTF-8 encoding of the message is: Umberto Ecn\n"
     ]
    }
   ],
   "source": [
    "import devoir1\n",
    "question1 = devoir1.codeBreaker_RSA()\n",
    "\n",
    "msg = question1.Decipher(q1_N,q1_e, q1_C)\n",
    "print(\"The deciphered M is: \"+str(msg))\n",
    "print(\"The UTF-8 encoding of the message is: \"+question1.int_to_str(msg))\n",
    "\n",
    "# Main reference : e-th root attack\n",
    "# https://crypto.stackexchange.com/questions/33561/cube-root-attack-rsa-with-low-exponent\n",
    "# but, in hindsight, class handout already hinted at root 3.... welp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what the actual M should be without data imprecision: Umberto Eco\n"
     ]
    }
   ],
   "source": [
    "print(\"what the actual M should be without data imprecision: \"+question1.int_to_str(msg+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual original string should probably be \"Umberto Eco\" which gives a M of 103275247704828660521722735 (which is our M+1)\n",
    "\n",
    "This difference is probably due to our nth-root attack implementation uses C**(1/e) to calculate n-th root. If there is a way to calculate n-th root without the division then there would probably be a lot less precision loss.\n",
    "\n",
    "And also, if there is no division, we wouldn't have to transform integer values into Decimal (because these int are too big for a division resulting in float, so we need to use Decimal division operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N length is reasonable for an exhaustive attack\n",
      "Expected runtime: 0.0 minutes\n",
      "intermediate result is: 26\n",
      "N=33 E=13 C=26, M should be 5? 5\n"
     ]
    }
   ],
   "source": [
    "# A form of meet-in-middle (in name only) exhaustive attack is also implemented to break RSA that don't satisfy the n-th root attack condition but still short enough\n",
    "# I've set it to allow exhaustive attack on RSA with bit length shorter than 51 \n",
    "\n",
    "# why 51? because I was brute-forcing Q1.2 with it and it can run through 1mil options in under 10 seconds...  of course as it gets longer the time cost will increase linearly\n",
    "# limit being it can only calculate small value enough to be stored in np uint64 (so the upper bit length limit is 64).\n",
    "# Python Int can be way longer and in that case we must use np array dtype=object, but in that case the speed would be at least 100 times slower\n",
    "# although, if we really do exhaustive attack on 64 bit, it would take at least a whole day... in the scope of this homework I deem this unreasonable time.\n",
    "# So I limit it to only do exhaustive attack if N bit length is less than 51 (worst expected runtime about 10 minutes?)\n",
    "\n",
    "# using the RSA example given in class handouts\n",
    "print(\"N=33 E=13 C=26, M should be 5? \"+str(question1.Decipher(33, 13, 26)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot perform attack on such RSA within reasonable timeframe.\n",
      "The deciphered M is: OPERATION ABORTED\n"
     ]
    }
   ],
   "source": [
    "# Clé publique Question 1.2\n",
    "q2_N = 172219604291138178634924980176652297603347655313304280071646410523864939208855547078498922947475940487766894695848119416017067844129458299713889703424997977808694983717968420001033168722360067307143390485095229367172423195469582545920975539060699530956357494837243598213416944408434967474317474605697904676813343577310719430442085422937057220239881971046349315235043163226355302567726074269720408051461805113819456513196492192727498270702594217800502904761235711809203123842506621973488494670663483187137290546241477681096402483981619592515049062514180404818608764516997842633077157249806627735448350463\n",
    "q2_e = 173\n",
    "\n",
    "# Cryptogramme 1.2\n",
    "q2_C = 25782248377669919648522417068734999301629843637773352461224686415010617355125387994732992745416621651531340476546870510355165303752005023118034265203513423674356501046415839977013701924329378846764632894673783199644549307465659236628983151796254371046814548224159604302737470578495440769408253954186605567492864292071545926487199114612586510433943420051864924177673243381681206265372333749354089535394870714730204499162577825526329944896454450322256563485123081116679246715959621569603725379746870623049834475932535184196208270713675357873579469122917915887954980541308199688932248258654715380981800909\n",
    "\n",
    "print(\"The deciphered M is: \"+str(question1.Decipher(q2_N,q2_e, q2_C)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I cannot find known weaknesses when e is bigger than 3, and with this length it's pratically impossible to break using exhaustive methods.\n",
    "\n",
    "I've seen that some suggest Coppersmith method, and it does seem to break Q1.1 efficiently (tested on CoCalc, return the accurate result with no data loss, but CoCalc does not allow calculating Q1.2 due to long calculation time). But I can't get Sagemath to work locally on my setup, as such I cannot test its performance on Q1.2 and I can't tell whether Coppersmith's performance on Q1.1 is proof of it being a good method, or it was due Q1.1 being too weak.\n",
    "\n",
    "...and also, with a N of 2001 bit-length I doubt any conventional method can break it in a reasonable timeframe... (especially when I re-read the class handout and was reminded that the world record for RSA break was only on a 800 bit length... RSA is good for a reason, and those people are way smarter and they probably used everything they have. If even them cannot handle such N, I doubt I can do it with my limited knowledge)\n",
    "\n",
    "But! although the length of C and N is beyond my capabilities, the length of M (therefore, the possible range values of M) is much much smaller, and we can probably brute-force it. \n",
    "\n",
    "Like in the case of \"Umberto Eco\", its UTF-8 int form has a bit-length less than 90, and it has a possiblity range of 2**(11*8) = 309,485,009,821,345,068,724,781,056 = 256**11 (the UTF-8 form of it)\n",
    "\n",
    "But, since we know the plaintext is a name, and a name does not use all possible range of a UTF-8 encoding (we dont use characters such as + - ( ) 1 2 3 4 in a name, and we only use capital letter at the beginning of a name), and so the possible range of a name is possibily millions time smaller than computing integer possibilities.\n",
    "\n",
    "I was about to write a name generator to test that out, but this is where I re-read the question, and it specified \"auteur célèbre\", which is again a range of possibility much much smaller than the possible range of all names.\n",
    "\n",
    "If it's famous, then it probably has a Wikipedia page. And if its in the category of 'auteur', then there is probably a category page on Wikipedia. And I was right.\n",
    "\n",
    "So, I went on Wikipedia and copied all their entry names in the author category :\n",
    "\n",
    "from \n",
    "https://en.wikipedia.org/wiki/List_of_authors_by_name:_A\n",
    "to\n",
    "https://en.wikipedia.org/wiki/List_of_authors_by_name:_Z\n",
    "\n",
    "(the list of names can be found in authors.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These 2 functions are copied from Devoir 1 Examples\n",
    "\n",
    "# convert string to list of integer\n",
    "def str_to_int_list(x):\n",
    "  z = [ord(a) for a in x  ]\n",
    "  for x in z:\n",
    "    if x > 256:\n",
    "      #print(x)\n",
    "      return False\n",
    "  return z\n",
    "\n",
    "# convert a strint to an integer\n",
    "def str_to_int(x):\n",
    "  x = str_to_int_list(x)\n",
    "  if x == False:\n",
    "    #print(\"Le text n'est pas compatible!\")\n",
    "    return False\n",
    "\n",
    "  res = 0\n",
    "  for a in x:\n",
    "    res = res * 256 + a\n",
    "  i = 0\n",
    "  res = \"\"\n",
    "  for a in x:\n",
    "    ci = \"{:08b}\".format(a )\n",
    "    #if len(ci)>8:\n",
    "      #print()\n",
    "      #print(\"long\",a)\n",
    "      #print()\n",
    "    res = res + ci\n",
    "  res = eval(\"0b\"+res)\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ciphered author name is: Marcel Proust\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Here, the list of author names are stored and parsed. The latter part in parenthesis are getting removed\n",
    "with open('authors.csv', newline='', encoding='utf8') as csvfile:\n",
    "    data = list(csv.reader(csvfile, delimiter='(')) # remove what comes after \"(\"\n",
    "\n",
    "# Now, we iterate through all author names, compute the corresponding C, and compare with the question.\n",
    "for index in range(len(data)):\n",
    "    name = data[index][0]\n",
    "    n = name[:len(name) - 1]    # cut out the last ' ' in name entry\n",
    "    i = str_to_int(n)\n",
    "\n",
    "    c = i**q2_e % q2_N\n",
    "    if (c == q2_C): # here, we get a match, so we print the author name and stop\n",
    "        print(\"The ciphered author name is: \"+n)\n",
    "        #print(c)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wouldn't be possible if the \"Auteur\" info was not available. \n",
    "\n",
    "Writing a name generator that would iterate through possible name combinations would be also quite tedious..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "A lot of attempts were made at finding weaknesses in the encryption, and it would probably take a week or longer to completely break the encryption.\n",
    "\n",
    "I will not detail all the methods that failed. I will detail here the only method that has seen success so far (and still it's not 100% reliable.)\n",
    "\n",
    "Also, all following conclusions were made under a few assumptions, so if any of these turns out to be false, then the whole thing will crumble.\n",
    "\n",
    "1. We know how the encryption algorithm work (such as UTF-8 encoding)\n",
    "2. We know it's encrypting French, and we know it has a curated list of symbols that tries to hide it.\n",
    "3. We have access to a large sample (or better, in this case, the original text) to perform text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import student_code as Q2   # this file also contains a lot of obsolete codes that were proven a waste of time.\n",
    "\n",
    "\n",
    "url = \"https://www.gutenberg.org/ebooks/13846.txt.utf-8\"  # Example URL (replace with your desired URL)\n",
    "corpus = Q2.load_text_from_web(url)\n",
    "url = \"https://www.gutenberg.org/ebooks/4650.txt.utf-8\"  # Example URL (replace with your desired URL)\n",
    "corpus = corpus + Q2.load_text_from_web(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first core weakness to this substitution cipher, is the fact it cannot hide repeating characters. Here's some examples:\n",
    "\n",
    "- ******'\n",
    "- '\\r\\n\\r\\n\\r\\n\\r\\n'\n",
    "- '           ' (consecutive space)\n",
    "\n",
    "Among these, the \\r\\n repeat is the core weakness that we exploit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__ maxConsec 8 total 584\n",
      "rn maxConsec 8 total 15428\n",
      "nr maxConsec 7 total 1562\n"
     ]
    }
   ],
   "source": [
    "print(\"__ maxConsec \"+str(Q2.checkConsecutiveChar(corpus, '  ',2,False)) +\" total \"+ str(Q2.countWord(corpus, '  ',2)))\n",
    "print(\"rn maxConsec \"+str(Q2.checkConsecutiveChar(corpus, '\\r\\n',2,False)) +\" total \"+ str(Q2.countWord(corpus, '\\r\\n', 2)))\n",
    "print(\"nr maxConsec \"+str(Q2.checkConsecutiveChar(corpus, '\\n\\r',2,False)) +\" total \"+ str(Q2.countWord(corpus, '\\n\\r', 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One might ask, how did I end up homing on \\r\\n ?\n",
    "Here is how.\n",
    "\n",
    "During one of my previous attempts, I made a list of monogram and bigrams all in the corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstats_ngram_1 = Q2.loadStatsNgram(\\'freq_ngram_1.csv\\')\\nindex = 1\\nfor x in stats_ngram_1:\\n    index += 2\\n    repeat = Q2.checkConsecutiveChar(corpus, x[0],1,False)\\n    if repeat > 3 : print(\"symbol \"+str(x[0])+\" index \"+str(index)+ \" maxrepeat \"+ str(repeat))\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find Symbol Repeat on ngram-1\n",
    "# The below code loads a list of precalculated monograms, and for each count their consecutive appearance.\n",
    "\n",
    "'''\n",
    "stats_ngram_1 = Q2.loadStatsNgram('freq_ngram_1.csv')\n",
    "index = 1\n",
    "for x in stats_ngram_1:\n",
    "    index += 2\n",
    "    repeat = Q2.checkConsecutiveChar(corpus, x[0],1,False)\n",
    "    if repeat > 3 : print(\"symbol \"+str(x[0])+\" index \"+str(index)+ \" maxrepeat \"+ str(repeat))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code takes 37.2s to run. So I disabled it, and here's the output\n",
    "\n",
    "```\n",
    "symbol   index 3 maxrepeat 16\n",
    "symbol . index 57 maxrepeat 4\n",
    "symbol * index 165 maxrepeat 38\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__ maxConsec 8 total 584\n",
      "rn maxConsec 8 total 15428\n",
      "nr maxConsec 7 total 1562\n"
     ]
    }
   ],
   "source": [
    "# Find Symbol Repeat on ngram-2\n",
    "# Only the first... 500? most frequent bigrams are written. and \\r \\n special characters are causing troubles.\n",
    "'''\n",
    "stats_ngram_2 = Q2.loadStatsNgram('freq_ngram_2.csv')\n",
    "index = 1\n",
    "for x in stats_ngram_2:\n",
    "    index += 2\n",
    "    repeat = Q2.checkConsecutiveChar(corpus, x[0],2,False)\n",
    "    if repeat > 3 : print(\"symbol \"+str(x[0])+\" index \"+str(index)+ \" maxrepeat \"+ str(repeat))\n",
    "'''\n",
    "# the above code will return '  ', because I probably messed up encoding and \\r\\n cannot be read... anyway, since it takes 2 min or longer, I will spare the run here.\n",
    "\n",
    "# the below 3 options are the standouts.\n",
    "print(\"__ maxConsec \"+str(Q2.checkConsecutiveChar(corpus, '  ',2,False)) +\" total \"+ str(Q2.countWord(corpus, '  ',2)))\n",
    "print(\"rn maxConsec \"+str(Q2.checkConsecutiveChar(corpus, '\\r\\n',2,False)) +\" total \"+ str(Q2.countWord(corpus, '\\r\\n', 2)))\n",
    "print(\"nr maxConsec \"+str(Q2.checkConsecutiveChar(corpus, '\\n\\r',2,False)) +\" total \"+ str(Q2.countWord(corpus, '\\n\\r', 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "._ maxConsec 1 total 202\n",
      "* maxConsec 0 total 0\n",
      "nr maxConsec 4 total 94\n",
      "rn maxConsec 5 total 729\n"
     ]
    }
   ],
   "source": [
    "# This part of code is used to verify the significance of \\r\\n in the corpus text.\n",
    "# Simply rerun this code to generate another sample. \\r\\n always has the most count\n",
    "\n",
    "import random\n",
    "\n",
    "a = random.randint(3400, 7200)\n",
    "b = random.randint(36000, 65000)\n",
    "l = a+b\n",
    "c = random.randint(0, len(corpus)-l)\n",
    "\n",
    "M = corpus[c:c+l]\n",
    "# . is masked by ._\n",
    "#print(\". maxConsec \"+str(Q2.checkConsecutiveChar(M, '.',1,False)) +\" total \"+ str(Q2.countWord(M, '.',1)))\n",
    "print(\"._ maxConsec \"+str(Q2.checkConsecutiveChar(M, '. ',2,False)) +\" total \"+ str(Q2.countWord(M, '. ', 2)))\n",
    "\n",
    "print(\"* maxConsec \"+str(Q2.checkConsecutiveChar(M, '*',1,False)) +\" total \"+ str(Q2.countWord(M, '*',1)))\n",
    "print(\"nr maxConsec \"+str(Q2.checkConsecutiveChar(M, '\\n\\r',2,False)) +\" total \"+ str(Q2.countWord(M, '\\n\\r', 2)))\n",
    "print(\"rn maxConsec \"+str(Q2.checkConsecutiveChar(M, '\\r\\n',2,False)) +\" total \"+ str(Q2.countWord(M, '\\r\\n', 2)))\n",
    "\n",
    "# of course, this info is based on the fact we know '.' is being masked by '. '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the proper code, the part that target and find \\r\\n is between Line 31 and Line 90.\n",
    "\n",
    "Now that we have a target, we need codes to find it in corpus text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is only capable of handling string character. A modifier version that handles array tables are in student_code.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# This code takes in a target symbol (eolSymbol), and count the specified count of symbol before or after the target symbol.\n",
    "def countEOL(corpus, eolSymbol = '\\r\\n', eolSymbolLen = 2, countSymbol = -1):\n",
    "    word = eolSymbol\n",
    "    array = []\n",
    "    wordlen = eolSymbolLen\n",
    "\n",
    "    start = -countSymbol\n",
    "\n",
    "    if start < 0: start = 0\n",
    "\n",
    "    for x in range(start, len(corpus) - wordlen):\n",
    "      if corpus[x:x+wordlen] == word:\n",
    "        if countSymbol < 0: array.append(corpus[x+countSymbol:x])\n",
    "        else: array.append(corpus[x+wordlen:x+wordlen+countSymbol])\n",
    "    return array\n",
    "\n",
    "# The result of countEOL should be feed to sortEOL (sort in descending order) to find the max count\n",
    "def sortEOL(arr):\n",
    "  sorted = []\n",
    "  nparr = np.unique(arr, return_counts=True, return_index=True)\n",
    "  sort = np.flip(nparr[2].argsort())\n",
    "  for x in sort:\n",
    "    arrayIndex = nparr[1][x]\n",
    "    sorted.append([arr[arrayIndex],nparr[2][x]])\n",
    "  return sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 2 symbols before rn\n",
      "['\\r\\n', np.int64(1561)]\n",
      "['es', np.int64(999)]\n",
      "['de', np.int64(640)]\n",
      "['nt', np.int64(598)]\n",
      "['re', np.int64(432)]\n",
      "\n",
      "Count 1 symbols before rn\n",
      "['e', np.int64(3351)]\n",
      "['s', np.int64(2214)]\n",
      "['t', np.int64(1711)]\n",
      "['\\n', np.int64(1561)]\n",
      "['.', np.int64(1242)]\n"
     ]
    }
   ],
   "source": [
    "# Count 2 symbol before \\r\\n\n",
    "print(\"Count 2 symbols before rn\")\n",
    "array = countEOL(corpus, eolSymbol='\\r\\n', eolSymbolLen= 2, countSymbol=-2)\n",
    "sorted = sortEOL(array)\n",
    "for x in sorted[:5]:\n",
    "   print(x)\n",
    "\n",
    "print(\"\\nCount 1 symbols before rn\")\n",
    "array = countEOL(corpus, eolSymbol='\\r\\n', eolSymbolLen= 2, countSymbol=-1)\n",
    "sorted = sortEOL(array)\n",
    "for x in sorted[:5]:\n",
    "   print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers seems to indicate we should target 'es' and 'e' next.\n",
    "\n",
    "But, real test shows otherwise.\n",
    "\n",
    "With \\r\\n decoded we can already see the text getting cut into paragraphs. Some lines are longer due to them using 't\\r' 'e\\r' and 's\\r', these we cannot detect just yet. So, since we have full paragraphs, we know a paragraph of text must end in '.'. \n",
    "\n",
    "If we peek at the dictionary, we know there's only '.' and '. ', and knowing French, we can exclude the 2nd option.\n",
    "\n",
    "So, next step we target '.'\n",
    "\n",
    "Codes at Line 95 - Line 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['es', np.int64(123)]\n",
      "['re', np.int64(75)]\n",
      "['nt', np.int64(63)]\n",
      "['le', np.int64(57)]\n",
      "[' B', np.int64(42)]\n"
     ]
    }
   ],
   "source": [
    "# Count 2 symbol before '.\\r\\n'\n",
    "array = countEOL(corpus, eolSymbol='.\\r\\n', eolSymbolLen= 3, countSymbol=-2)\n",
    "sorted = sortEOL(array)\n",
    "for x in sorted[:5]:\n",
    "   print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could try to count the frequency of symbols before '.', but this result is not very encouraging simply because we only found the end-of-paragraph '.' and not the mid-paragraph '.', so the sample size are too small.\n",
    "\n",
    "Here's the central assumption of the algorithm.\n",
    "\n",
    "It assumes the next symbol after \\r\\n is 'qu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\r\\n', np.int64(1562)]\n",
      "['qu', np.int64(694)]\n",
      "['de', np.int64(513)]\n",
      "['co', np.int64(492)]\n",
      "['le', np.int64(320)]\n"
     ]
    }
   ],
   "source": [
    "# Count 2 symbol after \\r\\n\n",
    "array = countEOL(corpus, eolSymbol='\\r\\n', eolSymbolLen= 2, countSymbol=2)\n",
    "sorted = sortEOL(array)\n",
    "for x in sorted[:5]:\n",
    "   print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that although not massive, 'qu' still has a lead over the rest. But still, it is a massive assumption, and this is what drives the success rate of the algorithm down.\n",
    "\n",
    "But, assuming we can find 'qu'...\n",
    "1. We can then find 'quelqu'\n",
    "2. We can find 'quelque ' and 'quelques'\n",
    "\n",
    "'qu' finder code at L115 - L130\n",
    "\n",
    "'el' 'e ' 'es' finder code at L145 -  L165, and all called functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e ', np.int64(363)]\n",
      "['es', np.int64(165)]\n",
      "['ef', np.int64(49)]\n",
      "['e\\r', np.int64(38)]\n",
      "[\"'u\", np.int64(34)]\n"
     ]
    }
   ],
   "source": [
    "array = countEOL(corpus, eolSymbol='quelqu', eolSymbolLen= 6, countSymbol=2)\n",
    "#print(array[:20])\n",
    "sorted = sortEOL(array)\n",
    "for x in sorted[:5]:\n",
    "   print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. With 'es' nailed down, we can also proceed to 'es les' and 'es des'. \n",
    "\n",
    "One peek at the dictionary tells us that ' l' and ' d' are both used, so if we see 2 decoded 'es' surrounding a single symbol, the middle symbol is guaranteed to be either ' l' and ' d'.\n",
    "\n",
    "Codes at L165 - L175"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. With 'es' and 'qu' nailed, we can also find 'qui est'.\n",
    "\n",
    "One thing worthy of note is that we have 't ' and 't\\r', both of them should be considered when decoding this.\n",
    "\n",
    "Codes at L175 - L190"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, this is as far as I got.\n",
    "\n",
    "So many of the frequency analysis codes were written and re-written, and most of them turned out to be unhelpful or unreliable. The whole breakthrough with \\r\\n was only achieved this Sunday morning...\n",
    "\n",
    "So far, the highest decrypt rate acheved is 0.54%, with all mentionned symbols decrypted.\n",
    "If luck is not on my side and we failed to find 'qu', then the result is gibberish.\n",
    "\n",
    "And also, all this is based on so many assumptions. If anything were changed (such as one symbol changed in the dictionary), then the whole process need to start over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport test\\n\\nt1 = test.TestDecryption()\\nt1.test_decryption_accuracy()\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A piece of code to quickly run test\n",
    "'''\n",
    "import test\n",
    "\n",
    "t1 = test.TestDecryption()\n",
    "t1.test_decryption_accuracy()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sample of decryption result (taken from github autograder's run result)\n",
    "\n",
    "Decrypted symbols:\n",
    "```\n",
    "{'38': '\\r\\n', '124': '.', '224': 'qu', '55': 'el', '20': 'e ', '64': 'es', '10': ' l', '220': ' d', '101': 'i ', '112': 't '}\n",
    "```\n",
    "\n",
    "```text\n",
    "-n puissance, quoiqu'elles ne se\n",
    "-produisent pas encore et ne se fassent point paroître par leurs actions.\n",
    "-En effet, j'expérimente déjà que ma connoissance s'augmente et se\n",
    "-perfectionne peu à peu; et je ne vois rien qui puisse empêcher qu'elle\n",
    "-ne s'augmente ainsi de plus eu plus jusques à l'infini, ni aussi\n",
    "-pourquoi, étant ainsi accrue et perfectionnée, je ne pourrois pas\n",
    "-acquérir par son moyen toutes les autres perfections de la nature\n",
    "-divine, ni enfin pourquoi la puissance que j'ai pour l'acquisition de\n",
    "-ces perfections, s'il est vrai qu'elle soit maintenant en moi, ne seroit\n",
    "-pas suffisante pour en produire les idées. Toutefois, en y regardant\n",
    "-un peu de près, je reconnois que cela ne peut être; car premièrement,\n",
    "-encore qu'il fût vrai que ma connoissance acquît tous les jours de\n",
    "-nouveaux degrés de perfection, et qu'il y eût en ma nature beaucoup de\n",
    "-choses en puissance qui n'y sont pas encore actuellement, toutefois tous\n",
    "-ces avantages n'appartiennent et n'approchent en aucune sorte de l'idée\n",
    "-que j'ai de la Divinité, dans laquelle rien ne se rencontre seulement en\n",
    "-puissance, mais tout y est actuellement et en effet. Et même n'est-ce\n",
    "-pas un argument infaillible et très certain d'imperfection en ma\n",
    "-connoissance, de ce qu'elle s'accroît peu à peu et qu'elle s'augmente\n",
    "-par degrés? De plus, encore que ma connoissance s'augmentât de plus en\n",
    "-plus, néanmoins je ne laisse pas de concevoir qu'elle ne sauroit être\n",
    "-actuellement infinie, puisqu'elle n'arrivera jamais à un si haut point\n",
    "-de perfection, qu'elle ne soit encore capable d'acquérir quelque plus\n",
    "-grand accroissement. Mais je conçois Dieu actuellement infini en un si\n",
    "-haut degré, qu'il ne se peut rien ajouter à la souveraine perfection\n",
    "-qu'il possède. Et, enfin, je comprends fort bien que l'être objectif\n",
    "-d'une idée ne peut être produit par un être qui existe seulement en\n",
    "-puissance, lequel à proprement parler n'est rien, mais seulement par un\n",
    "-être formel ou actuel.\n",
    "-\n",
    "-Et certes je ne vois rien en tout ce que je viens de dire qui ne soit\n",
    "\n",
    "+???????qu?qu??es?e ?\n",
    "+???????????e ??e ?????????????e ??????????.\n",
    "+???????????????e ???que ???????e ??????e ???????????????????e ???????????e ???????el?\n",
    "+???????e ??i ??????????ques? l??????????\n",
    "+??qu????t ??i ??????t ???????????e ??????\n",
    "+??qu??????????????????es???????? l???????????i ??????qu? l??????????i ?? l??qu?????\n",
    "+????????????est ??i qu??e ???????t ??????????????????????????? les??es????????????????\n",
    "+??? de ????e ?????que ???e ?????????????????\n",
    "+????????t ??i que ???????e ??qu?t ?? les??? d??????? d????????????????????t ??????e ?????? d????es??????????????t ??????????????????????\n",
    "+??????es????????t ????????t ?????e ??e ? l????que ??i ? l?????????? l?quel??????e ????e ???????\n",
    "+??????????t ??????????t ?????????t ????????\n",
    "+???????????????e ?????????????????????\n",
    "+?????????e qu??e ??????t ????????el??????????????????e ???????????????????????t ?????\n",
    "+???????????e ????? de ???????el??e ???t ???????????t ????????qu??e ?????????????????t ????????????qu??e ???t ???????e ???qu???quelque ??\n",
    "+???????????????????????????????t ???i ????\n",
    "+??t ????qu????e ?????????????????e ??????\n",
    "+qu???????????????????????t ???que ???e ??????\n",
    "+???e ???e ?????e ????t ??????e qui ???????????\n",
    "+???????quel??????t ??????????????????????\n",
    "+??e ??????????.\n",
    "+\n",
    "+?t ??es?e ???????????e que ???? de ?????e ??\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
